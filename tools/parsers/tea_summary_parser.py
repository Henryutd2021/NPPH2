#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TEA Summary Report Parsing Script
Parse TEA Summary Reports from 42 reactors and organize data into structured Excel output
Based on the new report format generated by src/tea/reporting.py
"""

import os
import re
import pandas as pd
import numpy as np
from pathlib import Path
import logging
from typing import Dict, Any, Optional

# Setup logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def _parse_value(value_str: str) -> Any:
    """Universal value parsing function, handles numbers, percentages, currency and N/A"""
    if value_str is None or not value_str.strip():
        return np.nan

    s = value_str.strip()

    # Handle explicit "N/A" cases
    if s in ['N/A', 'None', '--', '']:
        return np.nan

    # Remove explanatory text in parentheses
    if '(' in s and ')' in s:
        s = re.sub(r'\([^)]*\)', '', s).strip()

    # Handle negative numbers with minus sign first
    negative_sign = ''
    if s.startswith('-'):
        negative_sign = '-'
        s = s[1:]

    # Handle negative numbers in parentheses
    if s.startswith('(') and s.endswith(')'):
        negative_sign = '-'
        s = s[1:-1]

    # Remove currency symbols, commas, units
    s = re.sub(r'[$,]', '', s)
    s = re.sub(r'\s*(kg|MWh|MW|MWt|years?|%|USD|/kg|/MWh|/year|/hr|/day)\s*$',
               '', s, flags=re.IGNORECASE)

    # Re-apply negative sign if needed
    if negative_sign:
        s = negative_sign + s

    # Try to convert to number
    try:
        if '.' in s:
            return float(s)
        return int(s)
    except (ValueError, TypeError):
        return s


def _extract_aligned_values(section_content: str, patterns: Dict[str, str]) -> Dict[str, Any]:
    """Extract values from aligned format sections (name : value)"""
    data = {}

    for key, pattern in patterns.items():
        try:
            # 修改正则表达式来更好地匹配对齐格式，允许多个空格
            modified_pattern = pattern.replace(r'\s*:\s*', r'\s*:\s*')
            match = re.search(modified_pattern, section_content,
                              re.DOTALL | re.MULTILINE)
            if match:
                value = match.group(1) if match.groups() else match.group(0)
                data[key] = _parse_value(value)
            else:
                data[key] = np.nan
        except re.error as e:
            logger.error(
                f"Invalid regex pattern for key '{key}': {pattern} - {e}")
            data[key] = np.nan

    return data


class TEASummaryParser:
    def __init__(self, tea_output_dir: str = "output/tea/cs1"):
        self.tea_output_dir = Path(tea_output_dir)
        self.all_reactor_data = {}

    def parse_all_reactors(self) -> Dict[str, Dict[str, Any]]:
        """Parse all reactor folders for TEA Summary Reports"""
        reactor_folders = [
            d for d in self.tea_output_dir.iterdir() if d.is_dir()]
        logger.info(f"Found {len(reactor_folders)} reactor folders")

        for folder in reactor_folders:
            reactor_name = folder.name
            logger.info(f"Processing: {reactor_name}")

            # Look for TEA Summary Report files
            tea_files = list(folder.glob("*TEA_Summary_Report.txt"))

            if tea_files:
                tea_file = tea_files[0]  # Take the first match
                try:
                    with open(tea_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                    parsed_data = self._parse_file_content(content)
                    parsed_data['reactor_name'] = reactor_name
                    parsed_data['file_path'] = str(tea_file)
                    self.all_reactor_data[reactor_name] = parsed_data

                except Exception as e:
                    logger.error(
                        f"Failed to parse file {tea_file}: {e}", exc_info=True)
            else:
                logger.warning(
                    f"TEA Summary Report not found in: {reactor_name}")

        logger.info(
            f"Successfully parsed {len(self.all_reactor_data)} reactors")
        return self.all_reactor_data

    def _parse_file_content(self, content: str) -> Dict[str, Any]:
        """Parse complete file content"""
        data = {}

        # Split content into sections
        sections = self._split_into_sections(content)

        # Parse each section
        data.update(self._parse_configuration(sections.get(1, "")))
        data.update(self._parse_financial_performance(sections.get(2, "")))
        data.update(self._parse_system_performance(sections.get(3, "")))
        data.update(self._parse_cost_analysis(sections.get(4, "")))
        data.update(self._parse_revenue_analysis(sections.get(5, "")))
        data.update(self._parse_advanced_financial(sections.get(6, "")))
        data.update(self._parse_comparative_analysis(sections.get(7, "")))

        return data

    def _split_into_sections(self, content: str) -> Dict[int, str]:
        """Split content into numbered sections"""
        sections = {}

        # Split by section headers (1., 2., 3., etc.)
        section_pattern = r'\n(?=\d+\.\s+[A-Za-z])'
        parts = re.split(section_pattern, content)

        for part in parts:
            part = part.strip()
            if not part:
                continue

            # Extract section number
            match = re.match(r'(\d+)\.\s+', part)
            if match:
                section_num = int(match.group(1))
                sections[section_num] = part

        return sections

    def _parse_configuration(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 1: Executive Summary & Configuration"""
        patterns = {
            'iso_region': r'ISO Region\s*:\s*([A-Z]+)',
            'project_lifetime_years': r'Project Lifetime\s*:\s*([\d.]+)',
            'construction_period_years': r'Construction Period\s*:\s*([\d.]+)',
            'discount_rate_percent': r'Discount Rate\s*:\s*([\d.]+)',
            'corporate_tax_rate_percent': r'Corporate Tax Rate\s*:\s*([\d.]+)',
            'turbine_capacity_mw': r'Turbine Capacity\s*:\s*([\d,]+\.?\d*)',
            'thermal_capacity_mwt': r'Thermal Capacity\s*:\s*([\d,]+\.?\d*)',
            'thermal_efficiency': r'Thermal Efficiency\s*:\s*([\d.]+)',
            'electrolyzer_capacity_mw': r'Electrolyzer Capacity\s*:\s*([\d,]+\.?\d*)',
            'h2_storage_capacity_kg': r'Hydrogen Storage Capacity\s*:\s*([\d,]+\.?\d*)',
            'battery_energy_capacity_mwh': r'Battery Energy Capacity\s*:\s*([\d,]+\.?\d*)',
            'battery_power_capacity_mw': r'Battery Power Capacity\s*:\s*([\d,]+\.?\d*)',
            'h2_constant_sales_rate_kg_hr': r'Optimal H2 Constant Sales Rate\s*:\s*([\d,]+\.?\d*)',
            'h2_daily_sales_rate_kg_day': r'Optimal H2 Daily Sales Rate\s*:\s*([\d,]+\.?\d*)',
            'h2_annual_sales_rate_kg_year': r'Optimal H2 Annual Sales Rate\s*:\s*([\d,]+\.?\d*)',
        }
        return _extract_aligned_values(section_content, patterns)

    def _parse_financial_performance(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 2: Financial Performance Summary"""
        patterns = {
            'irr_percent': r'IRR\s*\(%\)\s*:\s*([\d.]+)%?',
            'lcoh_usd_per_kg': r'LCOH\s*\(USD/kg\)\s*:\s*\$?([\d.]+)',
            'npv_usd': r'NPV\s*\(USD\)\s*:\s*\$?([\d,.-]+)',
            'payback_period_years': r'Payback\s+Period\s*\(Years\)\s*:\s*([\d.]+)',
            'total_annual_revenue': r'Total\s+Annual\s+Revenue\s*:\s*\$?([\d,.-]+)',
            'energy_revenue': r'Energy\s+Revenue\s*:\s*\$?([\d,.-]+)',
            'h2_sales_revenue': r'H2\s+Sales\s+Revenue\s*:\s*\$?([\d,.-]+)',
            'h2_subsidy_revenue': r'H2\s+Subsidy\s+Revenue\s*:\s*\$?([\d,.-]+)',
            'ancillary_services_revenue': r'Ancillary\s+Services\s+Revenue\s*:\s*\$?([\d,.-]+)',
        }
        return _extract_aligned_values(section_content, patterns)

    def _parse_system_performance(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 3: System Performance Analysis"""
        patterns = {
            'annual_h2_production_kg': r'Annual\s+H2\s+Production\s*:\s*([\d,]+)',
            'daily_h2_production_kg': r'Daily\s+H2\s+Production\s*:\s*([\d,]+)',
            'annual_nuclear_generation_mwh': r'Annual\s+Nuclear\s+Generation\s*:\s*([\d,]+)',
            'annual_electrolyzer_consumption_mwh': r'Annual\s+Electrolyzer\s+Consumption\s*:\s*([\d,]+)',
            'h2_production_efficiency_kg_per_mwh': r'H2\s+Production\s+Efficiency\s*:\s*([\d.]+)',
            'electrolyzer_capacity_factor_percent': r'Electrolyzer\s+Capacity\s+Factor\s*:\s*([\d.]+)%?',
            'turbine_capacity_factor_percent': r'Turbine\s+Capacity\s+Factor\s*:\s*([\d.]+)%?',
            'h2_storage_average_soc_percent': r'H2\s+Storage\s+Average\s+SOC\s*:\s*([\d.]+)%?',
            'battery_average_soc_percent': r'Battery\s+Average\s+SOC\s*:\s*([\d.]+)%?',
        }

        data = _extract_aligned_values(section_content, patterns)

        # Parse additional performance metrics from section 3.3
        additional_patterns = {
            'as_revenue_total': r'AS\s+Revenue\s+Total\s*:\s*\$?([\d,.-]+)',
            'as_revenue_per_mw_electrolyzer': r'AS\s+Revenue\s+per\s+MW\s+Electrolyzer\s*:\s*\$?([\d,.-]+)',
            'avg_electricity_price_usd_per_mwh': r'Avg\s+Electricity\s+Price\s+USD\s+per\s+MWh\s*:\s*\$?([\d.]+)',
            'weighted_avg_electricity_price_usd_per_mwh': r'Weighted\s+Avg\s+Electricity\s+Price\s+USD\s+per\s+MWh\s*:\s*\$?([\d.]+)',
            'nuclear_fixed_om_annual_usd': r'Nuclear\s+Fixed\s+OM\s+Annual\s+USD\s*:\s*\$?([\d,.-]+)',
            'nuclear_variable_om_annual_usd': r'Nuclear\s+Variable\s+OM\s+Annual\s+USD\s*:\s*\$?([\d,.-]+)',
            'nuclear_fuel_cost_annual_usd': r'Nuclear\s+Fuel\s+Cost\s+Annual\s+USD\s*:\s*\$?([\d,.-]+)',
            'total_system_opex_annual_usd': r'Total\s+System\s+OPEX\s+Annual\s+USD\s*:\s*\$?([\d,.-]+)',
        }
        data.update(_extract_aligned_values(
            section_content, additional_patterns))

        return data

    def _parse_cost_analysis(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 4: Cost Analysis"""
        data = {}

        # Extract CAPEX breakdown
        capex_patterns = {
            'electrolyzer_system_capex': r'Electrolyzer\s+System\s*:\s*\$?([\d,.-]+)',
            'h2_storage_system_capex': r'H2\s+Storage\s+System\s*:\s*\$?([\d,.-]+)',
            'grid_integration_capex': r'Grid\s+Integration\s*:\s*\$?([\d,.-]+)',
            'npp_modifications_capex': r'NPP\s+Modifications\s*:\s*\$?([\d,.-]+)',
            'total_capex': r'Total\s+CAPEX:\s*\$?([\d,.-]+)',
        }
        data.update(_extract_aligned_values(section_content, capex_patterns))

        # Extract OPEX breakdown
        opex_patterns = {
            'vom_turbine_cost': r'VOM\s+Turbine\s*:\s*\$?([\d,.-]+)',
            'vom_electrolyzer_cost': r'VOM\s+Electrolyzer\s*:\s*\$?([\d,.-]+)',
            'water_cost': r'Water\s+Cost\s*:\s*\$?([\d,.-]+)',
            'ramping_cost': r'Ramping\s+Cost\s*:\s*\$?([\d,.-]+)',
            'h2_storage_cycle_cost': r'H2\s+Storage\s+Cycle\s+Cost\s*:\s*\$?([\d,.-]+)',
            'nuclear_plant_opex': r'Nuclear\s+Plant\s+OPEX\s*:\s*\$?([\d,.-]+)',
            'total_annual_opex': r'Total\s+Annual\s+OPEX\s*:\s*\$?([\d,.-]+)',
        }
        data.update(_extract_aligned_values(section_content, opex_patterns))

        return data

    def _parse_revenue_analysis(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 5: Revenue Analysis"""
        patterns = {
            'total_ancillary_services_revenue': r'Total Ancillary Services Revenue\s*:\s*([\d,.-]+)',
            'as_revenue_percent_of_total': r'AS Revenue as % of Total Revenue\s*:\s*([\d.]+)',
        }

        data = _extract_aligned_values(section_content, patterns)

        # Battery performance if available
        battery_patterns = {
            'annual_battery_charge_mwh': r'Total Annual Charging\s*:\s*([\d,.-]+)',
            'battery_charge_from_grid_mwh': r'From Grid Purchase\s*:\s*([\d,.-]+)',
            'battery_charge_from_npp_mwh': r'From NPP \(Opportunity Cost\)\s*:\s*([\d,.-]+)',
        }
        data.update(_extract_aligned_values(section_content, battery_patterns))

        return data

    def _parse_advanced_financial(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 6: Advanced Financial Analysis"""
        data = {}

        # 45U Nuclear PTC Analysis
        ptc_patterns = {
            'nuclear_45u_credit_rate': r'Credit Rate\s*:\s*([\d.]+)',
            'nuclear_45u_annual_credit_value': r'Annual Credit Value\s*:\s*([\d,.-]+)',
            'nuclear_45u_total_credits': r'Total Credits Over Lifetime\s*:\s*([\d,.-]+)',
            'npv_without_45u': r'WITHOUT 45U Policy.*?NPV\s*:\s*([\d,.-]+)',
            'irr_without_45u': r'WITHOUT 45U Policy.*?IRR\s*:\s*([\d.]+)',
            'npv_with_45u': r'WITH 45U Policy.*?NPV\s*:\s*([\d,.-]+)',
            'irr_with_45u': r'WITH 45U Policy.*?IRR\s*:\s*([\d.]+)',
            'npv_improvement_from_45u': r'NPV Improvement\s*:\s*\+([\d,.-]+)',
        }
        data.update(_extract_aligned_values(section_content, ptc_patterns))

        # MACRS Analysis
        macrs_patterns = {
            'total_capex_subject_to_macrs': r'Total CAPEX Subject to MACRS\s*:\s*([\d,.-]+)',
            'total_macrs_depreciation': r'Total MACRS Depreciation\s*:\s*([\d,.-]+)',
            'total_tax_benefits_from_macrs': r'Total Tax Benefits from MACRS\s*:\s*([\d,.-]+)',
            'macrs_improvement_in_npv': r'MACRS Improvement in NPV\s*:\s*([\d,.-]+)',
        }
        data.update(_extract_aligned_values(section_content, macrs_patterns))

        # Incremental Analysis
        incremental_patterns = {
            'incremental_npv': r'Incremental Financial Results.*?NPV \(USD\)\s*:\s*([\d,.-]+)',
            'incremental_irr': r'Incremental Financial Results.*?IRR \(%\)\s*:\s*([\d.]+)',
            'incremental_payback': r'Incremental Financial Results.*?Payback Period \(Years\)\s*:\s*([\d.]+)',
            'total_incremental_capex': r'Total Incremental CAPEX \(USD\)\s*:\s*([\d,.-]+)',
            'annual_electricity_opportunity_cost': r'Annual Electricity Opportunity Cost \(USD\)\s*:\s*([\d,.-]+)',
            'incremental_roi': r'Incremental ROI\s*:\s*([\d.]+)',
        }
        data.update(_extract_aligned_values(
            section_content, incremental_patterns))

        # LCOH breakdown - 扩展所有组件（包括负值组件）
        lcoh_patterns = {
            'total_lcoh_detailed': r'Total LCOH:\s*\$([\d.]+)/kg H2',
            'lcoh_electricity_opportunity_cost': r'Electricity\s+Opportunity\s+Cost\s*:\s*\$([\d.-]+)/kg',
            'lcoh_electrolyzer_system': r'Electrolyzer\s+System\s*:\s*\$([\d.-]+)/kg',
            'lcoh_vom_electrolyzer': r'Vom\s+Electrolyzer\s*:\s*\$([\d.-]+)/kg',
            'lcoh_fixed_om': r'Fixed\s+Om\s*:\s*\$([\d.-]+)/kg',
            'lcoh_hte_heat_opportunity_cost': r'Hte\s+Heat\s+Opportunity\s+Cost\s*:\s*\$([\d.-]+)/kg',
            'lcoh_water_cost': r'Water\s+Cost\s*:\s*\$([\d.-]+)/kg',
            'lcoh_h2_storage_system': r'H2\s+Storage\s+System\s*:\s*\$([\d.-]+)/kg',
            'lcoh_h2_storage_cycle_cost': r'H2\s+Storage\s+Cycle\s+Cost\s*:\s*\$([\d.-]+)/kg',
            'lcoh_grid_integration': r'Grid\s+Integration\s*:\s*\$([\d.-]+)/kg',
            'lcoh_npp_modifications': r'NPP\s+Modifications\s*:\s*\$([\d.-]+)/kg',
            'lcoh_ramping_cost': r'Ramping\s+Cost\s*:\s*\$([\d.-]+)/kg',
            # 新增AS revenue deduction等负值组件
            'lcoh_as_revenue_deduction': r'As\s+Revenue\s+Deduction\s*:\s*\$\s*(-?[\d.]+)/kg',
            'lcoh_h2_system_as_revenue': r'H2\s+System\s+AS\s+Revenue\s*:\s*\$\s*(-?[\d.]+)/kg',
            # 通用负值组件
            'lcoh_negative_components': r'(\w+\s+\w*)\s*:\s*\$\s*-\s*([\d.]+)/kg',
        }
        data.update(_extract_aligned_values(section_content, lcoh_patterns))

        # LCOH Cost Category Analysis
        lcoh_category_patterns = {
            'lcoh_capital_recovery_capex': r'Capital\s+Recovery\s+\(CAPEX\)\s*:\s*\$([\d.]+)/kg',
            'lcoh_electricity_costs': r'Electricity\s+Costs\s*:\s*\$([\d.]+)/kg',
            'lcoh_fixed_om_category': r'Fixed\s+O&M\s*:\s*\$([\d.]+)/kg',
            'lcoh_variable_opex': r'Variable\s+OPEX\s*:\s*\$([\d.]+)/kg',
            'lcoh_equipment_replacements': r'Equipment\s+Replacements\s*:\s*\$([\d.]+)/kg',
        }
        data.update(_extract_aligned_values(
            section_content, lcoh_category_patterns))

        return data

    def _parse_comparative_analysis(self, section_content: str) -> Dict[str, Any]:
        """Parse Section 7: Comparative Analysis"""
        data = {}

        # Nuclear baseline analysis
        baseline_patterns = {
            'baseline_plant_name': r'Plant Name\s*:\s*([A-Za-z\s]+)',
            'baseline_turbine_capacity_mw': r'Turbine Capacity\s*:\s*([\d.]+)',
            'baseline_capacity_factor': r'Operational Capacity Factor\s*:\s*([\d.]+)',
            'baseline_annual_generation_mwh': r'Annual Generation\s*:\s*([\d,]+)',
            'baseline_annual_revenue': r'Annual Revenue\s*:\s*([\d,.-]+)',
            'baseline_total_annual_opex': r'Total Annual OPEX\s*:\s*([\d,.-]+)',
            'baseline_profit_margin': r'Profit Margin\s*:\s*([\d.-]+)',
            'baseline_npv': r'Net Present Value \(NPV\)\s*:\s*([\d,.-]+)',
        }
        data.update(_extract_aligned_values(
            section_content, baseline_patterns))

        # Greenfield analysis
        greenfield_patterns = {
            'greenfield_nuclear_capacity_mw': r'Nuclear Capacity\s*:\s*([\d,]+)',
            'greenfield_total_system_capex': r'Total System CAPEX\s*:\s*([\d,.-]+)',
            'greenfield_nuclear_capex': r'Nuclear Plant CAPEX\s*:\s*([\d,.-]+)',
            'greenfield_hydrogen_system_capex': r'Hydrogen System CAPEX\s*:\s*([\d,.-]+)',
            'greenfield_npv': r'Net Present Value \(NPV\)\s*:\s*([\d,.-]+)',
            'greenfield_irr': r'Internal Rate of Return \(IRR\)\s*:\s*([\d.]+)',
            'greenfield_payback': r'Payback Period\s*:\s*([\d.]+)',
            'greenfield_lcoh': r'LCOH \(Integrated System\)\s*:\s*([\d.]+)',
            'greenfield_nuclear_lcoe': r'Nuclear LCOE\s*:\s*([\d.]+)',
        }
        data.update(_extract_aligned_values(
            section_content, greenfield_patterns))

        return data

    def create_excel_output(self, output_file: str = "output/tea/tea_summary_analysis.xlsx"):
        """Create comprehensive Excel output with organized sheets"""
        if not self.all_reactor_data:
            logger.error("No data available to write to Excel file")
            return

        # Convert to DataFrame
        full_df = pd.DataFrame.from_dict(self.all_reactor_data, orient='index')
        full_df.reset_index(drop=True, inplace=True)

        # Ensure output directory exists
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:

            # 1. Executive Summary Sheet
            summary_cols = [
                'reactor_name', 'iso_region', 'turbine_capacity_mw', 'thermal_capacity_mwt',
                'npv_usd', 'irr_percent', 'lcoh_usd_per_kg', 'payback_period_years',
                'total_annual_revenue', 'annual_h2_production_kg', 'electrolyzer_capacity_mw'
            ]
            self._write_filtered_sheet(
                writer, 'Executive_Summary', full_df, summary_cols)

            # 2. Project Configuration Sheet
            config_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                                 ['iso_region', 'project_lifetime', 'construction_period', 'discount_rate',
                           'tax_rate', 'turbine_capacity', 'thermal_capacity', 'thermal_efficiency',
                                                                  'electrolyzer_capacity', 'h2_storage_capacity', 'battery_energy_capacity',
                                                                  'battery_power_capacity', 'h2_constant_sales', 'h2_daily_sales', 'h2_annual_sales'])]
            self._write_filtered_sheet(
                writer, 'Project_Configuration', full_df, config_cols)

            # 3. Financial Performance Sheet
            financial_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                                    ['npv', 'irr', 'lcoh', 'payback', 'revenue', 'roi'])]
            self._write_filtered_sheet(
                writer, 'Financial_Performance', full_df, financial_cols)

            # 4. System Performance Sheet
            performance_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                                      ['h2_production', 'nuclear_generation', 'electrolyzer_consumption',
                                                                       'capacity_factor', 'efficiency', 'soc', 'electricity_price'])]
            self._write_filtered_sheet(
                writer, 'System_Performance', full_df, performance_cols)

            # 5. Cost Analysis Sheet
            cost_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                               ['capex', 'opex', 'cost', 'vom', 'ramping', 'water'])]
            self._write_filtered_sheet(
                writer, 'Cost_Analysis', full_df, cost_cols)

            # 6. Revenue Analysis Sheet
            revenue_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                                  ['revenue', 'ancillary', 'sales', 'subsidy', 'energy_revenue'])]
            self._write_filtered_sheet(
                writer, 'Revenue_Analysis', full_df, revenue_cols)

            # 7. Advanced Financial Analysis Sheet
            advanced_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                                   ['45u', 'ptc', 'macrs', 'incremental', 'lcoh_', 'baseline', 'opportunity'])]
            self._write_filtered_sheet(
                writer, 'Advanced_Financial', full_df, advanced_cols)

            # 8. Comparative Analysis Sheet
            comparative_cols = [col for col in full_df.columns if any(x in col.lower() for x in
                                                                      ['baseline', 'greenfield', 'comparative'])]
            self._write_filtered_sheet(
                writer, 'Comparative_Analysis', full_df, comparative_cols)

            # 9. Complete Dataset
            self._write_filtered_sheet(
                writer, 'Complete_Dataset', full_df, full_df.columns.tolist())

        logger.info(f"Excel file created: {output_file}")
        logger.info(f"Total reactors processed: {len(full_df)}")
        logger.info(f"Total data columns: {len(full_df.columns)}")

    def _write_filtered_sheet(self, writer, sheet_name: str, df: pd.DataFrame, columns: list):
        """Write filtered data to Excel sheet"""
        # Filter columns that actually exist in the DataFrame
        existing_cols = [col for col in columns if col in df.columns]

        # Always include reactor_name if not already included
        if 'reactor_name' not in existing_cols and 'reactor_name' in df.columns:
            existing_cols = ['reactor_name'] + existing_cols

        if existing_cols:
            sheet_df = df[existing_cols].copy()
            sheet_df.to_excel(writer, sheet_name=sheet_name, index=False)
            logger.debug(
                f"Sheet '{sheet_name}' created with {len(existing_cols)} columns")
        else:
            logger.warning(
                f"No matching columns found for sheet '{sheet_name}'")

    def generate_summary_report(self, output_file: str = "output/tea/reactor_summary.txt"):
        """Generate a text summary report of key findings"""
        if not self.all_reactor_data:
            logger.error("No data available for summary report")
            return

        df = pd.DataFrame.from_dict(self.all_reactor_data, orient='index')

        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("TEA Summary Report - 42 Reactor Analysis\n")
            f.write("=" * 50 + "\n\n")

            f.write(f"Total reactors analyzed: {len(df)}\n")
            f.write(
                f"Analysis date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # Key statistics
            if 'npv_usd' in df.columns:
                positive_npv = (df['npv_usd'] > 0).sum()
                f.write(
                    f"Reactors with positive NPV: {positive_npv} / {len(df)}\n")
                f.write(f"Average NPV: ${df['npv_usd'].mean():,.0f}\n")
                f.write(f"Median NPV: ${df['npv_usd'].median():,.0f}\n\n")

            if 'irr_percent' in df.columns:
                f.write(f"Average IRR: {df['irr_percent'].mean():.2f}%\n")
                f.write(f"Median IRR: {df['irr_percent'].median():.2f}%\n\n")

            if 'lcoh_usd_per_kg' in df.columns:
                f.write(
                    f"Average LCOH: ${df['lcoh_usd_per_kg'].mean():.3f}/kg\n")
                f.write(
                    f"Median LCOH: ${df['lcoh_usd_per_kg'].median():.3f}/kg\n")
                below_target = (df['lcoh_usd_per_kg'] <= 2.0).sum()
                f.write(
                    f"Reactors meeting DOE $2/kg target: {below_target} / {len(df)}\n\n")

            # Top performers
            if 'npv_usd' in df.columns:
                f.write("Top 5 reactors by NPV:\n")
                top_npv = df.nlargest(5, 'npv_usd')[
                    ['reactor_name', 'npv_usd', 'irr_percent']]
                for _, row in top_npv.iterrows():
                    f.write(
                        f"  {row['reactor_name']}: NPV=${row['npv_usd']:,.0f}, IRR={row['irr_percent']:.2f}%\n")

        logger.info(f"Summary report created: {output_file}")


def main():
    """Main function to run the TEA Summary Parser"""
    parser = TEASummaryParser()

    # Parse all reactor data
    parser.parse_all_reactors()

    # Create Excel output
    parser.create_excel_output()

    # Generate summary report
    parser.generate_summary_report()

    logger.info("TEA Summary parsing completed successfully!")


if __name__ == "__main__":
    main()
